
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Run AI models in Java. Three lines of code, zero setup.">
      
      
      
        <link rel="canonical" href="https://inference4j.github.io/inference4j/generative-ai/introduction/">
      
      
        <link rel="prev" href="../../use-cases/text-to-sql/">
      
      
        <link rel="next" href="../chat-templates/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>Introduction - inference4j</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta http-equiv="Expires" content="0">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#generative-ai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="inference4j" class="md-header__button md-logo" aria-label="inference4j" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            inference4j
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/inference4j/inference4j" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    inference4j/inference4j
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="inference4j" class="md-nav__button md-logo" aria-label="inference4j" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    inference4j
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/inference4j/inference4j" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    inference4j/inference4j
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/how-it-works/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    How It Works
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Use Cases
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Use Cases
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/sentiment-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sentiment Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/semantic-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Semantic Search
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/image-classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/object-detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Object Detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/speech-to-text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Speech-to-Text
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/voice-activity-detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Voice Activity Detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/text-detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/visual-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Visual Search
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/summarization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Summarization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/translation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Translation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/grammar-correction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Grammar Correction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../use-cases/text-to-sql/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text-to-SQL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Generative AI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Generative AI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#two-approaches-to-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two approaches to generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Two approaches to generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-generation-inference4j-core" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native generation (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnxruntime-genai-inference4j-genai" class="md-nav__link">
    <span class="md-ellipsis">
      
        onnxruntime-genai (inference4j-genai)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#where-were-heading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where we're heading
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-autoregressive-loop" class="md-nav__link">
    <span class="md-ellipsis">
      
        The autoregressive loop
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The autoregressive loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        The KV cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Encoder-decoder models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Encoder-decoder models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#two-types-of-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two types of KV cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-the-two-approaches-differ" class="md-nav__link">
    <span class="md-ellipsis">
      
        How the two approaches differ
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supported models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Supported models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-generation-inference4j-core_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native generation (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#native-encoder-decoder-inference4j-core" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native encoder-decoder (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnxruntime-genai-inference4j-genai_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        onnxruntime-genai (inference4j-genai)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-templates/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chat Templates
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Native Generation
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Native Generation
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../native-text-generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    onnxruntime-genai
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    onnxruntime-genai
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi-vision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Phi-3.5 Vision
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Whisper Speech-to-Text
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/tokenizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tokenizers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/hardware-acceleration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hardware Acceleration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/spring-boot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Spring Boot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/model-loading/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Model Loading
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/supported-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Supported Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/clip-encoders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CLIP Encoders
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Contributing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/adding-a-wrapper/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding a Wrapper
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../roadmap/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Roadmap
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#two-approaches-to-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two approaches to generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Two approaches to generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-generation-inference4j-core" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native generation (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnxruntime-genai-inference4j-genai" class="md-nav__link">
    <span class="md-ellipsis">
      
        onnxruntime-genai (inference4j-genai)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#where-were-heading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where we're heading
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-autoregressive-loop" class="md-nav__link">
    <span class="md-ellipsis">
      
        The autoregressive loop
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The autoregressive loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        The KV cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Encoder-decoder models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Encoder-decoder models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#two-types-of-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two types of KV cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-the-two-approaches-differ" class="md-nav__link">
    <span class="md-ellipsis">
      
        How the two approaches differ
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supported models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Supported models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-generation-inference4j-core_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native generation (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#native-encoder-decoder-inference4j-core" class="md-nav__link">
    <span class="md-ellipsis">
      
        Native encoder-decoder (inference4j-core)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnxruntime-genai-inference4j-genai_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        onnxruntime-genai (inference4j-genai)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="generative-ai">Generative AI<a class="headerlink" href="#generative-ai" title="Permanent link">&para;</a></h1>
<p>Run autoregressive models — text generation, speech-to-text, and vision-language — directly in Java with token-by-token generation and streaming.</p>
<h2 id="two-approaches-to-generation">Two approaches to generation<a class="headerlink" href="#two-approaches-to-generation" title="Permanent link">&para;</a></h2>
<p>All models in inference4j outside this section are <strong>single-pass</strong> — one forward pass, one result. Generative models are fundamentally different. They produce output <strong>one token at a time</strong> in a loop, feeding each token back into the model to produce the next one. This loop requires managing a KV cache, token sampling, and stop conditions.</p>
<p>inference4j supports two approaches to running this loop:</p>
<h3 id="native-generation-inference4j-core">Native generation (inference4j-core)<a class="headerlink" href="#native-generation-inference4j-core" title="Permanent link">&para;</a></h3>
<p>inference4j implements the full autoregressive loop in Java on top of standard ONNX Runtime. This includes KV cache management, token sampling (temperature, top-K, top-P), BPE tokenization with decoding, and streaming — all built into <code>inference4j-core</code> with zero additional dependencies.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Works with any ONNX model that exports KV cache inputs/outputs — the standard HuggingFace ONNX export format</li>
<li>No extra native libraries beyond ONNX Runtime</li>
<li>Full control over the generation pipeline (sampling, stop sequences, token streaming)</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>The generation loop runs in Java rather than optimized C++, so it's slightly slower per token</li>
</ul>
<h3 id="onnxruntime-genai-inference4j-genai">onnxruntime-genai (inference4j-genai)<a class="headerlink" href="#onnxruntime-genai-inference4j-genai" title="Permanent link">&para;</a></h3>
<p><a href="https://github.com/microsoft/onnxruntime-genai">onnxruntime-genai</a> is a native library by Microsoft that handles the entire generation pipeline in optimized C++ — tokenization, the generation loop, KV cache, and sampling. inference4j wraps this library via the <code>inference4j-genai</code> module.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>The entire loop (including tokenization and KV cache) runs in native C++, maximizing throughput</li>
<li>Supports multimodal models (Phi-3.5 Vision) where image preprocessing is handled natively</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Models must be exported in onnxruntime-genai's specific format — few are available today</li>
<li>The library is in preview and community support is limited; Microsoft's investment appears to have slowed</li>
<li>Requires a separate native dependency (<code>onnxruntime-genai</code>) that we build and publish ourselves since Microsoft does not currently publish Java bindings to Maven Central</li>
<li>GPU support is not available in the Java bindings</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">onnxruntime-genai is experimental</p>
<p>The <code>inference4j-genai</code> module wraps a library in preview. We maintain the
<a href="https://github.com/inference4j/onnxruntime-genai">onnxruntime-genai Java build</a>
ourselves. The API may change between releases.</p>
</div>
<h3 id="where-were-heading">Where we're heading<a class="headerlink" href="#where-were-heading" title="Permanent link">&para;</a></h3>
<p>The native generation approach is the future. It unlocks any ONNX model on HuggingFace that exports with KV cache support — hundreds of models — without depending on a third-party native library. It supports both <strong>decoder-only</strong> models (GPT-2, SmolLM2, Qwen2.5, Gemma 2, TinyLlama) and <strong>encoder-decoder</strong> models (Flan-T5, BART, MarianMT, CoEdIT).</p>
<p>The onnxruntime-genai path remains valuable for models that need native multimodal preprocessing (like Phi-3.5 Vision) and for users who prefer the optimized C++ loop.</p>
<h2 id="the-autoregressive-loop">The autoregressive loop<a class="headerlink" href="#the-autoregressive-loop" title="Permanent link">&para;</a></h2>
<p>A generative model doesn't produce its entire output in a single forward pass.
It produces <strong>one token at a time</strong>. Each token is fed back into the model to produce
the next one, forming a loop that continues until the model emits a stop token or
reaches a maximum length.</p>
<pre class="mermaid"><code>flowchart TD
    A["Prompt tokens"] --&gt; B["Forward pass"]
    B --&gt; C["Next token"]
    C --&gt; D{"Stop token?"}
    D -- No --&gt; B
    D -- Yes --&gt; E["Complete text"]</code></pre>
<p>If you ask a model "What is Java?" and it generates a 50-token answer, the model runs
50 forward passes — one for each token in the response. This is why generation is
orders of magnitude slower than classification or embedding.</p>
<h3 id="the-kv-cache">The KV cache<a class="headerlink" href="#the-kv-cache" title="Permanent link">&para;</a></h3>
<p>There's a problem with the naive loop above. Each forward pass computes <strong>attention</strong>
over all previous tokens. Without optimization, generating token 50 would recompute
attention over all 49 previous tokens from scratch — the same work done for tokens
1 through 49, repeated entirely.</p>
<p>The <strong>KV cache</strong> (key-value cache) solves this. During each forward pass, the model
caches the intermediate key and value tensors from the attention layers. On the next
pass, only the new token's attention needs to be computed — everything from previous
tokens is read from the cache. This turns generation from O(n^2^) to O(n) in
sequence length.</p>
<h3 id="encoder-decoder-models">Encoder-decoder models<a class="headerlink" href="#encoder-decoder-models" title="Permanent link">&para;</a></h3>
<p>The models described above (GPT-2, SmolLM2, Qwen2.5) are <strong>decoder-only</strong> — they process the entire input and output as a single sequence. <strong>Encoder-decoder</strong> models split the work into two parts:</p>
<ol>
<li><strong>Encoder</strong>: processes the full input in a single forward pass, producing a rich representation of the input text</li>
<li><strong>Decoder</strong>: generates the output one token at a time, attending to the encoder's representation via <strong>cross-attention</strong></li>
</ol>
<p>This architecture is a natural fit for tasks where the input and output are structurally different — summarization (long article → short summary), translation (English → French), and grammar correction (broken text → fixed text).</p>
<pre class="mermaid"><code>flowchart TD
    A["Input text"] --&gt; B["Encoder&lt;br&gt;&lt;small&gt;single forward pass&lt;/small&gt;"]
    B --&gt; C["Encoder output&lt;br&gt;&lt;small&gt;frozen representation&lt;/small&gt;"]
    C --&gt; D["Decoder step 1&lt;br&gt;&lt;small&gt;cross-attention to encoder&lt;/small&gt;"]
    D --&gt; E["Token 1"]
    E --&gt; F["Decoder step 2"]
    F --&gt; G["Token 2"]
    G --&gt; H["..."]
    H --&gt; I{"Stop token?"}
    I -- No --&gt; J["Decoder step N"]
    I -- Yes --&gt; K["Complete output"]</code></pre>
<h4 id="two-types-of-kv-cache">Two types of KV cache<a class="headerlink" href="#two-types-of-kv-cache" title="Permanent link">&para;</a></h4>
<p>Encoder-decoder models maintain two separate caches:</p>
<ul>
<li><strong>Cross-attention cache</strong> — computed once from the encoder output after the first decoder step, then <strong>frozen</strong> for the rest of generation. This is what lets the decoder "look at" the input without recomputing it.</li>
<li><strong>Self-attention cache</strong> — grows with each decoder step, just like in decoder-only models. This cache stores the decoder's own previous states.</li>
</ul>
<p>This split is the key architectural difference from decoder-only models, where there is only one KV cache that grows throughout generation.</p>
<h3 id="how-the-two-approaches-differ">How the two approaches differ<a class="headerlink" href="#how-the-two-approaches-differ" title="Permanent link">&para;</a></h3>
<pre class="mermaid"><code>flowchart LR
    subgraph native["Native generation (inference4j-core)"]
        direction LR
        N1["BPE tokenize&lt;br&gt;&lt;small&gt;inference4j&lt;/small&gt;"]
        N2["Forward pass + KV cache&lt;br&gt;&lt;small&gt;ONNX Runtime&lt;/small&gt;"]
        N3["Sample + decode&lt;br&gt;&lt;small&gt;inference4j&lt;/small&gt;"]
        N1 --&gt; N2 --&gt; N3
    end

    subgraph genai["onnxruntime-genai (inference4j-genai)"]
        direction LR
        G1["Tokenize + Generate loop + KV cache + Sampling + Decode&lt;br&gt;&lt;small&gt;onnxruntime-genai (C++)&lt;/small&gt;"]
    end</code></pre>
<p>In native generation, inference4j handles tokenization, sampling, and decoding in Java while ONNX Runtime does the forward passes. In the genai path, the entire pipeline runs in onnxruntime-genai's native C++ layer.</p>
<h2 id="supported-models">Supported models<a class="headerlink" href="#supported-models" title="Permanent link">&para;</a></h2>
<h3 id="native-generation-inference4j-core_1">Native generation (inference4j-core)<a class="headerlink" href="#native-generation-inference4j-core_1" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Preset</th>
<th>Model ID</th>
<th>Parameters</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-2</td>
<td><code>OnnxTextGenerator.gpt2()</code></td>
<td><code>inference4j/gpt2</code></td>
<td>124M</td>
<td>~500 MB</td>
</tr>
<tr>
<td>SmolLM2-360M-Instruct</td>
<td><code>OnnxTextGenerator.smolLM2()</code></td>
<td><code>inference4j/smollm2-360m-instruct</code></td>
<td>360M</td>
<td>~700 MB</td>
</tr>
<tr>
<td>Qwen2.5-1.5B-Instruct</td>
<td><code>OnnxTextGenerator.qwen2()</code></td>
<td><code>inference4j/qwen2.5-1.5b-instruct</code></td>
<td>1.5B</td>
<td>~3 GB</td>
</tr>
</tbody>
</table>
<h3 id="native-encoder-decoder-inference4j-core">Native encoder-decoder (inference4j-core)<a class="headerlink" href="#native-encoder-decoder-inference4j-core" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Wrapper</th>
<th>Default Model ID</th>
<th>Parameters</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flan-T5 Small</td>
<td><code>FlanT5TextGenerator</code></td>
<td><code>inference4j/flan-t5-small</code></td>
<td>77M</td>
<td>~300 MB</td>
</tr>
<tr>
<td>Flan-T5 Base</td>
<td><code>FlanT5TextGenerator</code></td>
<td><code>inference4j/flan-t5-base</code></td>
<td>250M</td>
<td>~900 MB</td>
</tr>
<tr>
<td>Flan-T5 Large</td>
<td><code>FlanT5TextGenerator</code></td>
<td><code>inference4j/flan-t5-large</code></td>
<td>780M</td>
<td>~3 GB</td>
</tr>
<tr>
<td>DistilBART CNN 12-6</td>
<td><code>BartSummarizer</code></td>
<td><code>inference4j/distilbart-cnn-12-6</code></td>
<td>306M</td>
<td>~1.2 GB</td>
</tr>
<tr>
<td>BART Large CNN</td>
<td><code>BartSummarizer</code></td>
<td><code>inference4j/bart-large-cnn</code></td>
<td>406M</td>
<td>~1.6 GB</td>
</tr>
<tr>
<td>MarianMT</td>
<td><code>MarianTranslator</code></td>
<td>User-specified (<code>inference4j/opus-mt-*</code>)</td>
<td>varies</td>
<td>varies</td>
</tr>
<tr>
<td>CoEdIT Base</td>
<td><code>CoeditGrammarCorrector</code></td>
<td><code>inference4j/coedit-base</code></td>
<td>250M</td>
<td>~900 MB</td>
</tr>
<tr>
<td>CoEdIT Large</td>
<td><code>CoeditGrammarCorrector</code></td>
<td><code>inference4j/coedit-large</code></td>
<td>780M</td>
<td>~3 GB</td>
</tr>
<tr>
<td>T5-small-awesome-text-to-sql</td>
<td><code>T5SqlGenerator</code></td>
<td><code>inference4j/t5-small-awesome-text-to-sql</code></td>
<td>60M</td>
<td>~240 MB</td>
</tr>
<tr>
<td>T5-LM-Large-text2sql-spider</td>
<td><code>T5SqlGenerator</code></td>
<td><code>inference4j/T5-LM-Large-text2sql-spider</code></td>
<td>0.8B</td>
<td>~4.6 GB</td>
</tr>
</tbody>
</table>
<h3 id="onnxruntime-genai-inference4j-genai_1">onnxruntime-genai (inference4j-genai)<a class="headerlink" href="#onnxruntime-genai-inference4j-genai_1" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Wrapper</th>
<th>Model ID</th>
<th>Parameters</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Phi-3 Mini 4K Instruct</td>
<td><code>TextGenerator</code></td>
<td><code>inference4j/phi-3-mini-4k-instruct</code></td>
<td>3.8B</td>
<td>~2.7 GB</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Qwen-1.5B</td>
<td><code>TextGenerator</code></td>
<td><code>inference4j/deepseek-r1-distill-qwen-1.5b</code></td>
<td>1.5B</td>
<td>~1 GB</td>
</tr>
<tr>
<td>Whisper Small</td>
<td><code>WhisperSpeechModel</code></td>
<td><code>inference4j/whisper-small-genai</code></td>
<td>—</td>
<td>~500 MB</td>
</tr>
<tr>
<td>Phi-3.5 Vision Instruct</td>
<td><code>VisionLanguageModel</code></td>
<td><code>inference4j/phi-3.5-vision-instruct</code></td>
<td>4.2B</td>
<td>~3.3 GB</td>
</tr>
</tbody>
</table>
<p>All models are hosted on the
<a href="https://huggingface.co/inference4j">inference4j HuggingFace org</a>
and downloaded automatically on first use.</p>
<h2 id="next-steps">Next steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="../native-text-generation/">Native Text Generation</a> — GPT-2, SmolLM2, Qwen2.5 via OnnxTextGenerator (decoder-only)</li>
<li><a href="../../use-cases/summarization/">Summarization</a> — BartSummarizer, FlanT5TextGenerator (encoder-decoder)</li>
<li><a href="../../use-cases/translation/">Translation</a> — MarianTranslator, FlanT5TextGenerator (encoder-decoder)</li>
<li><a href="../../use-cases/grammar-correction/">Grammar Correction</a> — CoeditGrammarCorrector, FlanT5TextGenerator (encoder-decoder)</li>
<li><a href="../../use-cases/text-to-sql/">Text-to-SQL</a> — FlanT5TextGenerator (encoder-decoder)</li>
<li><a href="../chat-templates/">Chat Templates</a> — how prompt formatting works across models</li>
<li><a href="../text-generation/">Text Generation (onnxruntime-genai)</a> — Phi-3, DeepSeek-R1 via onnxruntime-genai</li>
<li><a href="../whisper/">Whisper Speech-to-Text</a> — transcription and translation via onnxruntime-genai</li>
<li><a href="../phi-vision/">Phi-3.5 Vision</a> — image description and visual Q&amp;A via onnxruntime-genai</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.indexes", "content.code.copy", "content.code.annotate", "search.highlight"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>